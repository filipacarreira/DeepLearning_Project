{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from os import path\n",
    "from numpy.random import seed\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from keras import layers,models\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tensorflow import random as tfrandom\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback, CSVLogger\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import math\n",
    "#from tensorflow import set_random_seed\n",
    "import cv2\n",
    "\n",
    "# to assure reproducibility\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Utilizador\\\\Desktop\\\\2_semestre_DS\\\\Deep_Learning\\\\DL_GroupProject\\\\DeepLearning_Group_Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=(base_path+r\"\\tumor_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the images to 1_xx, 2_xx, 3_xx, by the labels \n",
    "\n",
    "for _, letter in enumerate(os.listdir(dir_path)):\n",
    "    folder_letter = os.path.join(dir_path, letter)\n",
    " \n",
    "    counts=0\n",
    "    for _, image in enumerate(os.listdir(folder_letter)):\n",
    "        \n",
    "        dst=image\n",
    "    \n",
    "        if '_' in dst:\n",
    "            continue\n",
    "        else:\n",
    "            dst = str(letter) + \"_\" + str(counts) + \".png\"\n",
    "            #print(dst)\n",
    "            src = os.path.join(folder_letter, image)\n",
    "            dst = os.path.join(folder_letter, dst)\n",
    "            print(counts)\n",
    "            os.rename(src, dst)\n",
    "            \n",
    "        counts=counts+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories for the train, val and test splits\n",
    "train_path = os.path.join(dir_path, 'train')\n",
    "val_path = os.path.join(dir_path, 'validation')\n",
    "test_path = os.path.join(dir_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdir(mydir):\n",
    "    try:\n",
    "        os.mkdir(mydir)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "# create the directories\n",
    "\n",
    "createdir(train_path)\n",
    "createdir(val_path)\n",
    "createdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directories for each label for each train, validation and test folders\n",
    "count=0\n",
    "for dir in [train_path, val_path, test_path]:\n",
    "    count+=1\n",
    "    for letter in ['1','2','3']:\n",
    "        if count == 1:\n",
    "            createdir(os.path.join(dir,str(\"train_{0}\".format(str(letter)))))\n",
    "        elif count == 2:\n",
    "            createdir(os.path.join(dir,str(\"val_{0}\".format(str(letter)))))   \n",
    "        elif count == 3:\n",
    "            createdir(os.path.join(dir,str(\"test_{0}\".format(str(letter)))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "break\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# copy all the images for the train folder to then split them for validation and test folders \n",
    "\n",
    "count=0\n",
    "\n",
    "for dir_ in [train_path+r'\\train_1', train_path+r'\\train_2', train_path+r'\\train_3']:\n",
    "        if len(os.listdir(dir_)) != 0:\n",
    "            print('break')\n",
    "            for f in os.listdir(dir_):\n",
    "                os.remove(os.path.join(dir_, f))\n",
    "                \n",
    "for dir in [dir_path+r\"\\1\", dir_path+r\"\\2\", dir_path+r\"\\3\"]:\n",
    "    count+=1\n",
    "    \n",
    "    if count == 1:\n",
    "        copy_tree(dir, train_path+r'\\train_1')\n",
    "    elif count==2:\n",
    "        copy_tree(dir, train_path+r'\\train_2')\n",
    "    elif count==3:\n",
    "        copy_tree(dir, train_path+r'\\train_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion we want for train, val_test and the test datasets\n",
    "prop_train=0.80\n",
    "prop_val_test=0.20\n",
    "prop_test=0.50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'label1':708,'label2':1426,'label3':930}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "break\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# input images in VALIDATION\n",
    "\n",
    "count=0\n",
    "for index, letter in enumerate(os.listdir(train_path)):\n",
    "    count+=1\n",
    "    folder_letter_source = os.path.join(train_path, letter)\n",
    "    folder_letter_destiny_val = os.path.join(val_path, str(\"val_{0}\".format(str(count))))\n",
    "\n",
    "    images_val = random.sample(os.listdir(folder_letter_source), k=round(prop_val_test*labels['label{0}'.format(str(count))]))\n",
    "    count1=0\n",
    "    \n",
    "    for image in images_val:\n",
    "        count1+=1\n",
    "        if count1==1 and len(os.listdir(folder_letter_destiny_val)) != 0:\n",
    "            print('break')\n",
    "            for f in os.listdir(folder_letter_destiny_val):\n",
    "                os.remove(os.path.join(folder_letter_destiny_val, f))\n",
    "            \n",
    "        src = os.path.join(folder_letter_source, image)\n",
    "        dst = os.path.join(folder_letter_destiny_val, image)\n",
    "        shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label1': 142, 'label2': 285, 'label3': 186}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label1']=round(labels['label1']*prop_val_test)\n",
    "labels['label2']=round(labels['label2']*prop_val_test)\n",
    "labels['label3']=round(labels['label3']*prop_val_test)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "break\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# input images in TEST\n",
    "\n",
    "count=0\n",
    "for index, letter in enumerate(os.listdir(val_path)):\n",
    "    count+=1\n",
    "    folder_letter_source = os.path.join(val_path, letter)\n",
    "    folder_letter_destiny_test = os.path.join(test_path, str(\"test_{0}\".format(str(count))))\n",
    "\n",
    "    images_val = random.sample(os.listdir(folder_letter_source), k=round(prop_test*labels['label{0}'.format(str(count))]))\n",
    "    count1=0\n",
    "    \n",
    "    for image in images_val:\n",
    "        count1+=1\n",
    "        if count1==1 and len(os.listdir(folder_letter_destiny_test)) != 0:\n",
    "            print('break')\n",
    "            for f in os.listdir(folder_letter_destiny_test):\n",
    "                os.remove(os.path.join(folder_letter_destiny_test, f))\n",
    "            \n",
    "        src = os.path.join(folder_letter_source, image)\n",
    "        dst = os.path.join(folder_letter_destiny_test, image)\n",
    "        shutil.move(src, dst)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen_aug=ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    #rotation_range=50,\n",
    "                    rotation_range=10,\n",
    "                    shear_range=0.05)\n",
    "                    #horizontal_flip=True )\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 images belonging to 3 classes.\n",
      "Found 307 images belonging to 3 classes.\n",
      "Found 306 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(150, 150),  \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(150, 150), \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 images belonging to 3 classes.\n",
      "Found 307 images belonging to 3 classes.\n",
      "Found 306 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator_rgb = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "val_generator_rgb = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(150, 150),  \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "test_generator_rgb = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(150, 150), \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_times(model, times,name_model):\n",
    "  \n",
    "    times_dict = {'Model': ['Model {}'.format(str(name_model))]}\n",
    "    for idx, time in enumerate(times):\n",
    "        times_dict[idx] = times[idx]\n",
    "    df_save_times = pd.DataFrame(times_dict)\n",
    "\n",
    "    if os.path.exists(r'.\\models\\models_times.csv'):\n",
    "        df_save_times.to_csv(r'.\\models\\models_times.csv', mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df_save_times.to_csv(r'.\\models\\models_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(his):\n",
    "    f1 = his['f1_m']\n",
    "    f1_val=his['val_f1_m']\n",
    "    loss = his['loss']\n",
    "    loss_val=his['val_loss']\n",
    "\n",
    "    epochs=range(1,len(f1)+1)\n",
    "\n",
    "    plt.plot(epochs, f1,'bo',label='Training F1')\n",
    "    plt.plot(epochs, f1_val,'b',label='Validation F1')\n",
    "    plt.title('Training and Validation F1 score')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs, loss_val,'b',label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(filename):\n",
    "  callname_list=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=4),\n",
    "            keras.callbacks.ModelCheckpoint(filepath=os.path.join(base_path+ \"\\models\")+filename, monitor='val_loss',mode='min',verbose=1, save_best_only=True)\n",
    "            ,time_callback]\n",
    "\n",
    "  return callname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=20 \n",
    "TRAINING_SIZE = 2451 \n",
    "VALIDATION_SIZE = 307 \n",
    "\n",
    "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / BATCH_SIZE)) \n",
    "steps_per_epoch = compute_steps_per_epoch(TRAINING_SIZE) \n",
    "val_steps = compute_steps_per_epoch(VALIDATION_SIZE) \n",
    "\n",
    "print(steps_per_epoch)\n",
    "print(val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {\n",
    "    'f1_m': f1_m\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW = callback(\"\\modelBW.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.8476 - f1_m: 0.4821\n",
      "Epoch 00001: val_loss improved from inf to 0.66116, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 113s 918ms/step - loss: 0.8476 - f1_m: 0.4821 - val_loss: 0.6612 - val_f1_m: 0.6964\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6195 - f1_m: 0.7136\n",
      "Epoch 00002: val_loss improved from 0.66116 to 0.55743, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 110s 897ms/step - loss: 0.6195 - f1_m: 0.7136 - val_loss: 0.5574 - val_f1_m: 0.7547\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4924 - f1_m: 0.7831\n",
      "Epoch 00003: val_loss did not improve from 0.55743\n",
      "123/123 [==============================] - 110s 892ms/step - loss: 0.4924 - f1_m: 0.7831 - val_loss: 0.5582 - val_f1_m: 0.7619\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4262 - f1_m: 0.8177\n",
      "Epoch 00004: val_loss improved from 0.55743 to 0.40988, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 109s 886ms/step - loss: 0.4262 - f1_m: 0.8177 - val_loss: 0.4099 - val_f1_m: 0.8412\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3509 - f1_m: 0.8548\n",
      "Epoch 00005: val_loss improved from 0.40988 to 0.36651, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 109s 887ms/step - loss: 0.3509 - f1_m: 0.8548 - val_loss: 0.3665 - val_f1_m: 0.8352\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2765 - f1_m: 0.8856\n",
      "Epoch 00006: val_loss improved from 0.36651 to 0.30152, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 109s 884ms/step - loss: 0.2765 - f1_m: 0.8856 - val_loss: 0.3015 - val_f1_m: 0.8723\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2325 - f1_m: 0.9065\n",
      "Epoch 00007: val_loss did not improve from 0.30152\n",
      "123/123 [==============================] - 109s 883ms/step - loss: 0.2325 - f1_m: 0.9065 - val_loss: 0.3134 - val_f1_m: 0.8665\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1876 - f1_m: 0.9226\n",
      "Epoch 00008: val_loss did not improve from 0.30152\n",
      "123/123 [==============================] - 108s 878ms/step - loss: 0.1876 - f1_m: 0.9226 - val_loss: 0.3053 - val_f1_m: 0.8653\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1528 - f1_m: 0.9442\n",
      "Epoch 00009: val_loss improved from 0.30152 to 0.24720, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 102s 827ms/step - loss: 0.1528 - f1_m: 0.9442 - val_loss: 0.2472 - val_f1_m: 0.8922\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1228 - f1_m: 0.9527\n",
      "Epoch 00010: val_loss did not improve from 0.24720\n",
      "123/123 [==============================] - 93s 758ms/step - loss: 0.1228 - f1_m: 0.9527 - val_loss: 0.3726 - val_f1_m: 0.8764\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0978 - f1_m: 0.9682\n",
      "Epoch 00011: val_loss improved from 0.24720 to 0.22065, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 93s 759ms/step - loss: 0.0978 - f1_m: 0.9682 - val_loss: 0.2207 - val_f1_m: 0.9136\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0812 - f1_m: 0.9728\n",
      "Epoch 00012: val_loss did not improve from 0.22065\n",
      "123/123 [==============================] - 545s 4s/step - loss: 0.0812 - f1_m: 0.9728 - val_loss: 0.2388 - val_f1_m: 0.8889\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0782 - f1_m: 0.9713\n",
      "Epoch 00013: val_loss did not improve from 0.22065\n",
      "123/123 [==============================] - 110s 890ms/step - loss: 0.0782 - f1_m: 0.9713 - val_loss: 0.2646 - val_f1_m: 0.9165\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0657 - f1_m: 0.9738\n",
      "Epoch 00014: val_loss did not improve from 0.22065\n",
      "123/123 [==============================] - 114s 929ms/step - loss: 0.0657 - f1_m: 0.9738 - val_loss: 0.2764 - val_f1_m: 0.9156\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0550 - f1_m: 0.9801\n",
      "Epoch 00015: val_loss improved from 0.22065 to 0.20903, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 116s 945ms/step - loss: 0.0550 - f1_m: 0.9801 - val_loss: 0.2090 - val_f1_m: 0.9484\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0473 - f1_m: 0.9862\n",
      "Epoch 00016: val_loss did not improve from 0.20903\n",
      "123/123 [==============================] - 108s 878ms/step - loss: 0.0473 - f1_m: 0.9862 - val_loss: 0.3019 - val_f1_m: 0.9125\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0370 - f1_m: 0.9898\n",
      "Epoch 00017: val_loss did not improve from 0.20903\n",
      "123/123 [==============================] - 107s 874ms/step - loss: 0.0370 - f1_m: 0.9898 - val_loss: 0.7772 - val_f1_m: 0.8478\n",
      "Epoch 18/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0422 - f1_m: 0.9869\n",
      "Epoch 00018: val_loss did not improve from 0.20903\n",
      "123/123 [==============================] - 112s 913ms/step - loss: 0.0422 - f1_m: 0.9869 - val_loss: 0.2752 - val_f1_m: 0.9250\n",
      "Epoch 19/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0371 - f1_m: 0.9882\n",
      "Epoch 00019: val_loss did not improve from 0.20903\n",
      "123/123 [==============================] - 117s 955ms/step - loss: 0.0371 - f1_m: 0.9882 - val_loss: 0.2733 - val_f1_m: 0.9175\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[f1_m])\n",
    "\n",
    "history_1st = model.fit_generator(train_generator, callbacks=callbacks_BW, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW.npy',history_1st.history)\n",
    "modelBW = keras.models.load_model('models/modelBW.h5', custom_objects=dependencies)\n",
    "historyBW=np.load('models/historyBW.npy',allow_pickle='TRUE').item()\n",
    "timesBW = time_callback.times\n",
    "save_times(modelBW, timesBW,'modelBW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(historyBW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_inc = callback(\"\\modelBW_inc.h5\")\n",
    "#increase the nr of filters through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.8051 - f1_m: 0.5324\n",
      "Epoch 00001: val_loss improved from inf to 0.63319, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 71s 576ms/step - loss: 0.8051 - f1_m: 0.5324 - val_loss: 0.6332 - val_f1_m: 0.6955\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5951 - f1_m: 0.7319\n",
      "Epoch 00002: val_loss improved from 0.63319 to 0.57052, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 58s 470ms/step - loss: 0.5951 - f1_m: 0.7319 - val_loss: 0.5705 - val_f1_m: 0.6973\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4877 - f1_m: 0.7917\n",
      "Epoch 00003: val_loss improved from 0.57052 to 0.52632, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 62s 505ms/step - loss: 0.4877 - f1_m: 0.7917 - val_loss: 0.5263 - val_f1_m: 0.7543\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4005 - f1_m: 0.8360\n",
      "Epoch 00004: val_loss improved from 0.52632 to 0.40282, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 59s 480ms/step - loss: 0.4005 - f1_m: 0.8360 - val_loss: 0.4028 - val_f1_m: 0.8299\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3219 - f1_m: 0.8675\n",
      "Epoch 00005: val_loss improved from 0.40282 to 0.34943, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 59s 482ms/step - loss: 0.3219 - f1_m: 0.8675 - val_loss: 0.3494 - val_f1_m: 0.8527\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2574 - f1_m: 0.8966\n",
      "Epoch 00006: val_loss did not improve from 0.34943\n",
      "123/123 [==============================] - 61s 494ms/step - loss: 0.2574 - f1_m: 0.8966 - val_loss: 0.3729 - val_f1_m: 0.8361\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2085 - f1_m: 0.9138\n",
      "Epoch 00007: val_loss improved from 0.34943 to 0.28960, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 62s 504ms/step - loss: 0.2085 - f1_m: 0.9138 - val_loss: 0.2896 - val_f1_m: 0.8982\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1593 - f1_m: 0.9364\n",
      "Epoch 00008: val_loss improved from 0.28960 to 0.26882, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 69s 557ms/step - loss: 0.1593 - f1_m: 0.9364 - val_loss: 0.2688 - val_f1_m: 0.8859\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1135 - f1_m: 0.9573\n",
      "Epoch 00009: val_loss improved from 0.26882 to 0.21312, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 61s 498ms/step - loss: 0.1135 - f1_m: 0.9573 - val_loss: 0.2131 - val_f1_m: 0.9084\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0970 - f1_m: 0.9648\n",
      "Epoch 00010: val_loss did not improve from 0.21312\n",
      "123/123 [==============================] - 63s 514ms/step - loss: 0.0970 - f1_m: 0.9648 - val_loss: 0.6741 - val_f1_m: 0.8228\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0760 - f1_m: 0.9744\n",
      "Epoch 00011: val_loss did not improve from 0.21312\n",
      "123/123 [==============================] - 73s 591ms/step - loss: 0.0760 - f1_m: 0.9744 - val_loss: 0.2639 - val_f1_m: 0.9250\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0629 - f1_m: 0.9762\n",
      "Epoch 00012: val_loss improved from 0.21312 to 0.18831, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 64s 523ms/step - loss: 0.0629 - f1_m: 0.9762 - val_loss: 0.1883 - val_f1_m: 0.9281\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0541 - f1_m: 0.9840\n",
      "Epoch 00013: val_loss did not improve from 0.18831\n",
      "123/123 [==============================] - 70s 569ms/step - loss: 0.0541 - f1_m: 0.9840 - val_loss: 0.2488 - val_f1_m: 0.9344\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0392 - f1_m: 0.9870\n",
      "Epoch 00014: val_loss did not improve from 0.18831\n",
      "123/123 [==============================] - 67s 547ms/step - loss: 0.0392 - f1_m: 0.9870 - val_loss: 0.2198 - val_f1_m: 0.9192\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0353 - f1_m: 0.9884\n",
      "Epoch 00015: val_loss did not improve from 0.18831\n",
      "123/123 [==============================] - 60s 484ms/step - loss: 0.0353 - f1_m: 0.9884 - val_loss: 0.2012 - val_f1_m: 0.9312\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0239 - f1_m: 0.9919\n",
      "Epoch 00016: val_loss did not improve from 0.18831\n",
      "123/123 [==============================] - 59s 481ms/step - loss: 0.0239 - f1_m: 0.9919 - val_loss: 0.2089 - val_f1_m: 0.9469\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "model2.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[f1_m])\n",
    "\n",
    "history_2 = model2.fit_generator(train_generator, callbacks=callbacks_BW_inc, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_inc.npy',history_2.history)\n",
    "modelBW_inc = keras.models.load_model('models/modelBW_inc.h5', custom_objects=dependencies)\n",
    "historyBW_inc=np.load('models/historyBW_inc.npy',allow_pickle='TRUE').item()\n",
    "timesBW = time_callback.times\n",
    "save_times(modelBW_inc, timesBW,'modelBW_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(historyBW_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDUCING THE NUMBER OF LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_simple = callback(\"\\modelBW_simple.h5\")\n",
    "#increase the nr of filters through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7673 - f1_m: 0.5921\n",
      "Epoch 00001: val_loss improved from inf to 0.65803, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.7673 - f1_m: 0.5921 - val_loss: 0.6580 - val_f1_m: 0.7235\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5336 - f1_m: 0.7644\n",
      "Epoch 00002: val_loss improved from 0.65803 to 0.47772, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 69s 563ms/step - loss: 0.5336 - f1_m: 0.7644 - val_loss: 0.4777 - val_f1_m: 0.7817\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3725 - f1_m: 0.8408\n",
      "Epoch 00003: val_loss improved from 0.47772 to 0.40945, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.3725 - f1_m: 0.8408 - val_loss: 0.4094 - val_f1_m: 0.8278\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2553 - f1_m: 0.8965\n",
      "Epoch 00004: val_loss improved from 0.40945 to 0.28477, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 80s 653ms/step - loss: 0.2553 - f1_m: 0.8965 - val_loss: 0.2848 - val_f1_m: 0.8887\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1635 - f1_m: 0.9368\n",
      "Epoch 00005: val_loss improved from 0.28477 to 0.21020, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 81s 656ms/step - loss: 0.1635 - f1_m: 0.9368 - val_loss: 0.2102 - val_f1_m: 0.9116\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1228 - f1_m: 0.9587\n",
      "Epoch 00006: val_loss did not improve from 0.21020\n",
      "123/123 [==============================] - 80s 653ms/step - loss: 0.1228 - f1_m: 0.9587 - val_loss: 0.2401 - val_f1_m: 0.9085\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0912 - f1_m: 0.9644\n",
      "Epoch 00007: val_loss did not improve from 0.21020\n",
      "123/123 [==============================] - 83s 679ms/step - loss: 0.0912 - f1_m: 0.9644 - val_loss: 0.2282 - val_f1_m: 0.9192\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0650 - f1_m: 0.9768\n",
      "Epoch 00008: val_loss improved from 0.21020 to 0.19091, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 84s 686ms/step - loss: 0.0650 - f1_m: 0.9768 - val_loss: 0.1909 - val_f1_m: 0.9482\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0437 - f1_m: 0.9858\n",
      "Epoch 00009: val_loss did not improve from 0.19091\n",
      "123/123 [==============================] - 83s 677ms/step - loss: 0.0437 - f1_m: 0.9858 - val_loss: 0.2983 - val_f1_m: 0.9062\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0299 - f1_m: 0.9895\n",
      "Epoch 00010: val_loss improved from 0.19091 to 0.16922, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 78s 633ms/step - loss: 0.0299 - f1_m: 0.9895 - val_loss: 0.1692 - val_f1_m: 0.9406\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0224 - f1_m: 0.9931\n",
      "Epoch 00011: val_loss did not improve from 0.16922\n",
      "123/123 [==============================] - 72s 586ms/step - loss: 0.0224 - f1_m: 0.9931 - val_loss: 0.2078 - val_f1_m: 0.9379\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0165 - f1_m: 0.9931\n",
      "Epoch 00012: val_loss improved from 0.16922 to 0.16301, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 82s 670ms/step - loss: 0.0165 - f1_m: 0.9931 - val_loss: 0.1630 - val_f1_m: 0.9640\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0169 - f1_m: 0.9931\n",
      "Epoch 00013: val_loss did not improve from 0.16301\n",
      "123/123 [==============================] - 81s 658ms/step - loss: 0.0169 - f1_m: 0.9931 - val_loss: 0.2388 - val_f1_m: 0.9531\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0207 - f1_m: 0.9943\n",
      "Epoch 00014: val_loss did not improve from 0.16301\n",
      "123/123 [==============================] - 83s 677ms/step - loss: 0.0207 - f1_m: 0.9943 - val_loss: 0.2467 - val_f1_m: 0.9594\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0065 - f1_m: 0.9972\n",
      "Epoch 00015: val_loss improved from 0.16301 to 0.16150, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 73s 594ms/step - loss: 0.0065 - f1_m: 0.9972 - val_loss: 0.1615 - val_f1_m: 0.9562\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0171 - f1_m: 0.9943\n",
      "Epoch 00016: val_loss did not improve from 0.16150\n",
      "123/123 [==============================] - 75s 612ms/step - loss: 0.0171 - f1_m: 0.9943 - val_loss: 0.2068 - val_f1_m: 0.9687\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0096 - f1_m: 0.9973\n",
      "Epoch 00017: val_loss improved from 0.16150 to 0.14671, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 80s 651ms/step - loss: 0.0096 - f1_m: 0.9973 - val_loss: 0.1467 - val_f1_m: 0.9750\n",
      "Epoch 18/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0278 - f1_m: 0.9951\n",
      "Epoch 00018: val_loss did not improve from 0.14671\n",
      "123/123 [==============================] - 83s 673ms/step - loss: 0.0278 - f1_m: 0.9951 - val_loss: 0.2285 - val_f1_m: 0.9281\n",
      "Epoch 19/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0029 - f1_m: 0.9988\n",
      "Epoch 00019: val_loss did not improve from 0.14671\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.0029 - f1_m: 0.9988 - val_loss: 0.2323 - val_f1_m: 0.9437\n",
      "Epoch 20/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0126 - f1_m: 0.9980\n",
      "Epoch 00020: val_loss did not improve from 0.14671\n",
      "123/123 [==============================] - 76s 618ms/step - loss: 0.0126 - f1_m: 0.9980 - val_loss: 0.1984 - val_f1_m: 0.9625\n",
      "Epoch 21/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0156 - f1_m: 0.9967\n",
      "Epoch 00021: val_loss did not improve from 0.14671\n",
      "123/123 [==============================] - 78s 635ms/step - loss: 0.0156 - f1_m: 0.9967 - val_loss: 0.3117 - val_f1_m: 0.9562\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "\n",
    "model3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model3.add(layers.MaxPooling2D(2, 2))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D(2, 2))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D(2, 2))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(100, activation='relu'))\n",
    "model3.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[f1_m])\n",
    "\n",
    "history_3 = model3.fit_generator(train_generator, callbacks=callbacks_BW_simple, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_simple.npy',history_3.history)\n",
    "modelBW_simple = keras.models.load_model('models/modelBW_simple.h5', custom_objects=dependencies)\n",
    "historyBW_simple=np.load('models/historyBW_simple.npy',allow_pickle='TRUE').item()\n",
    "timesBW_simple = time_callback.times\n",
    "save_times(modelBW_simple, timesBW_simple,'modelBW_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION AND DROP OUT 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_5 = callback(\"\\modelBW_aug_5.h5\")\n",
    "# aug and dropout\n",
    "# modelBW_aug_rot= rotation10\n",
    "# modelBW_aug=rot50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7921 - f1_m: 0.5610\n",
      "Epoch 00001: val_loss improved from inf to 0.60428, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.7921 - f1_m: 0.5610 - val_loss: 0.6043 - val_f1_m: 0.7310\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5858 - f1_m: 0.7290\n",
      "Epoch 00002: val_loss improved from 0.60428 to 0.53367, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.5858 - f1_m: 0.7290 - val_loss: 0.5337 - val_f1_m: 0.7661\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4972 - f1_m: 0.7857\n",
      "Epoch 00003: val_loss did not improve from 0.53367\n",
      "123/123 [==============================] - 87s 711ms/step - loss: 0.4972 - f1_m: 0.7857 - val_loss: 0.5535 - val_f1_m: 0.7439\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4265 - f1_m: 0.8233\n",
      "Epoch 00004: val_loss improved from 0.53367 to 0.40904, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.4265 - f1_m: 0.8233 - val_loss: 0.4090 - val_f1_m: 0.8015\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3708 - f1_m: 0.8472\n",
      "Epoch 00005: val_loss improved from 0.40904 to 0.40070, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 710ms/step - loss: 0.3708 - f1_m: 0.8472 - val_loss: 0.4007 - val_f1_m: 0.8197\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3191 - f1_m: 0.8749\n",
      "Epoch 00006: val_loss did not improve from 0.40070\n",
      "123/123 [==============================] - 87s 709ms/step - loss: 0.3191 - f1_m: 0.8749 - val_loss: 0.4494 - val_f1_m: 0.8331\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2892 - f1_m: 0.8841\n",
      "Epoch 00007: val_loss improved from 0.40070 to 0.36519, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 707ms/step - loss: 0.2892 - f1_m: 0.8841 - val_loss: 0.3652 - val_f1_m: 0.8446\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2710 - f1_m: 0.8984\n",
      "Epoch 00008: val_loss improved from 0.36519 to 0.26549, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 707ms/step - loss: 0.2710 - f1_m: 0.8984 - val_loss: 0.2655 - val_f1_m: 0.8926\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2520 - f1_m: 0.9069\n",
      "Epoch 00009: val_loss did not improve from 0.26549\n",
      "123/123 [==============================] - 84s 679ms/step - loss: 0.2520 - f1_m: 0.9069 - val_loss: 0.2728 - val_f1_m: 0.9024\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2303 - f1_m: 0.9063\n",
      "Epoch 00010: val_loss improved from 0.26549 to 0.24523, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 66s 534ms/step - loss: 0.2303 - f1_m: 0.9063 - val_loss: 0.2452 - val_f1_m: 0.9004\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1937 - f1_m: 0.9198\n",
      "Epoch 00011: val_loss improved from 0.24523 to 0.24226, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 129s 1s/step - loss: 0.1937 - f1_m: 0.9198 - val_loss: 0.2423 - val_f1_m: 0.8831\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1895 - f1_m: 0.9256\n",
      "Epoch 00012: val_loss improved from 0.24226 to 0.24214, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 721s 6s/step - loss: 0.1895 - f1_m: 0.9256 - val_loss: 0.2421 - val_f1_m: 0.9036\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1675 - f1_m: 0.9345\n",
      "Epoch 00013: val_loss improved from 0.24214 to 0.16004, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 0.1675 - f1_m: 0.9345 - val_loss: 0.1600 - val_f1_m: 0.9452\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1515 - f1_m: 0.9414\n",
      "Epoch 00014: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 85s 693ms/step - loss: 0.1515 - f1_m: 0.9414 - val_loss: 0.2484 - val_f1_m: 0.8925\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1499 - f1_m: 0.9460\n",
      "Epoch 00015: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 88s 718ms/step - loss: 0.1499 - f1_m: 0.9460 - val_loss: 0.1634 - val_f1_m: 0.9348\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1359 - f1_m: 0.9500\n",
      "Epoch 00016: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 92s 745ms/step - loss: 0.1359 - f1_m: 0.9500 - val_loss: 0.1662 - val_f1_m: 0.9421\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1199 - f1_m: 0.9542\n",
      "Epoch 00017: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 0.1199 - f1_m: 0.9542 - val_loss: 0.3139 - val_f1_m: 0.8634\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(100, activation='relu'))\n",
    "model4.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[f1_m])\n",
    "\n",
    "history_4 = model4.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_5, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_aug_5.npy',history_4.history)\n",
    "modelBW_aug_5 = keras.models.load_model('models/modelBW_aug_5.h5', custom_objects=dependencies)\n",
    "historyBW_aug_5=np.load('models/historyBW_aug_5.npy',allow_pickle='TRUE').item()\n",
    "timesBW_aug_5 = time_callback.times\n",
    "save_times(modelBW_aug_5, timesBW_aug_5,'modelBW_aug_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65,   3,   3],\n",
       "       [ 11, 130,   1],\n",
       "       [  1,   0,  92]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelBW_aug_5.predict(test_generator)\n",
    "predicted_class_indices = np.argmax(preds, axis=1)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "cm = confusion_matrix(test_labels, predicted_class_indices)\n",
    "test_score = modelBW_aug_5.evaluate_generator(test_generator)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.23228779435157776 / Test accuracy: 0.9333332777023315\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {test_score[0]} / Test accuracy: {test_score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION with class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def generate_class_weights(class_series):\n",
    "\n",
    "  # If class is one hot encoded, transform to categorical labels to use compute_class_weight   \n",
    "\n",
    "  class_series = np.argmax(class_series, axis=1)\n",
    "\n",
    "  # Compute class weights with sklearn method\n",
    "  class_labels = np.unique(class_series)\n",
    "  class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=class_series)\n",
    "  return dict(zip(class_labels, class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator_aug.\n",
    "one_hot_labels = next(train_generator)[1]\n",
    "class_series = np.argmax(one_hot_labels, axis=1)\n",
    "\n",
    "# Compute class weights with sklearn method\n",
    "class_labels = np.unique(class_series)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=class_series)\n",
    "# class_weights=generate_class_weights(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_5 = callback(\"\\modelBW_aug_5.h5\")\n",
    "# aug and dropout\n",
    "# modelBW_aug_rot= rotation10\n",
    "# modelBW_aug=rot50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION AND DROP OUT 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_5 = callback(\"\\modelBW_aug_5.h5\")\n",
    "# aug and dropout\n",
    "# modelBW_aug_rot= rotation10\n",
    "# modelBW_aug=rot50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7921 - f1_m: 0.5610\n",
      "Epoch 00001: val_loss improved from inf to 0.60428, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.7921 - f1_m: 0.5610 - val_loss: 0.6043 - val_f1_m: 0.7310\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5858 - f1_m: 0.7290\n",
      "Epoch 00002: val_loss improved from 0.60428 to 0.53367, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.5858 - f1_m: 0.7290 - val_loss: 0.5337 - val_f1_m: 0.7661\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4972 - f1_m: 0.7857\n",
      "Epoch 00003: val_loss did not improve from 0.53367\n",
      "123/123 [==============================] - 87s 711ms/step - loss: 0.4972 - f1_m: 0.7857 - val_loss: 0.5535 - val_f1_m: 0.7439\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4265 - f1_m: 0.8233\n",
      "Epoch 00004: val_loss improved from 0.53367 to 0.40904, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.4265 - f1_m: 0.8233 - val_loss: 0.4090 - val_f1_m: 0.8015\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3708 - f1_m: 0.8472\n",
      "Epoch 00005: val_loss improved from 0.40904 to 0.40070, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 710ms/step - loss: 0.3708 - f1_m: 0.8472 - val_loss: 0.4007 - val_f1_m: 0.8197\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3191 - f1_m: 0.8749\n",
      "Epoch 00006: val_loss did not improve from 0.40070\n",
      "123/123 [==============================] - 87s 709ms/step - loss: 0.3191 - f1_m: 0.8749 - val_loss: 0.4494 - val_f1_m: 0.8331\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2892 - f1_m: 0.8841\n",
      "Epoch 00007: val_loss improved from 0.40070 to 0.36519, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 707ms/step - loss: 0.2892 - f1_m: 0.8841 - val_loss: 0.3652 - val_f1_m: 0.8446\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2710 - f1_m: 0.8984\n",
      "Epoch 00008: val_loss improved from 0.36519 to 0.26549, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 707ms/step - loss: 0.2710 - f1_m: 0.8984 - val_loss: 0.2655 - val_f1_m: 0.8926\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2520 - f1_m: 0.9069\n",
      "Epoch 00009: val_loss did not improve from 0.26549\n",
      "123/123 [==============================] - 84s 679ms/step - loss: 0.2520 - f1_m: 0.9069 - val_loss: 0.2728 - val_f1_m: 0.9024\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2303 - f1_m: 0.9063\n",
      "Epoch 00010: val_loss improved from 0.26549 to 0.24523, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 66s 534ms/step - loss: 0.2303 - f1_m: 0.9063 - val_loss: 0.2452 - val_f1_m: 0.9004\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1937 - f1_m: 0.9198\n",
      "Epoch 00011: val_loss improved from 0.24523 to 0.24226, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 129s 1s/step - loss: 0.1937 - f1_m: 0.9198 - val_loss: 0.2423 - val_f1_m: 0.8831\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1895 - f1_m: 0.9256\n",
      "Epoch 00012: val_loss improved from 0.24226 to 0.24214, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 721s 6s/step - loss: 0.1895 - f1_m: 0.9256 - val_loss: 0.2421 - val_f1_m: 0.9036\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1675 - f1_m: 0.9345\n",
      "Epoch 00013: val_loss improved from 0.24214 to 0.16004, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 0.1675 - f1_m: 0.9345 - val_loss: 0.1600 - val_f1_m: 0.9452\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1515 - f1_m: 0.9414\n",
      "Epoch 00014: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 85s 693ms/step - loss: 0.1515 - f1_m: 0.9414 - val_loss: 0.2484 - val_f1_m: 0.8925\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1499 - f1_m: 0.9460\n",
      "Epoch 00015: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 88s 718ms/step - loss: 0.1499 - f1_m: 0.9460 - val_loss: 0.1634 - val_f1_m: 0.9348\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1359 - f1_m: 0.9500\n",
      "Epoch 00016: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 92s 745ms/step - loss: 0.1359 - f1_m: 0.9500 - val_loss: 0.1662 - val_f1_m: 0.9421\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1199 - f1_m: 0.9542\n",
      "Epoch 00017: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 0.1199 - f1_m: 0.9542 - val_loss: 0.3139 - val_f1_m: 0.8634\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(100, activation='relu'))\n",
    "model4.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[f1_m])\n",
    "\n",
    "history_4 = model4.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_5, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_aug_5.npy',history_4.history)\n",
    "modelBW_aug_5 = keras.models.load_model('models/modelBW_aug_5.h5', custom_objects=dependencies)\n",
    "historyBW_aug_5=np.load('models/historyBW_aug_5.npy',allow_pickle='TRUE').item()\n",
    "timesBW_aug_5 = time_callback.times\n",
    "save_times(modelBW_aug_5, timesBW_aug_5,'modelBW_aug_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7921 - f1_m: 0.5610\n",
      "Epoch 00001: val_loss improved from inf to 0.60428, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.7921 - f1_m: 0.5610 - val_loss: 0.6043 - val_f1_m: 0.7310\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5858 - f1_m: 0.7290\n",
      "Epoch 00002: val_loss improved from 0.60428 to 0.53367, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.5858 - f1_m: 0.7290 - val_loss: 0.5337 - val_f1_m: 0.7661\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4972 - f1_m: 0.7857\n",
      "Epoch 00003: val_loss did not improve from 0.53367\n",
      "123/123 [==============================] - 87s 711ms/step - loss: 0.4972 - f1_m: 0.7857 - val_loss: 0.5535 - val_f1_m: 0.7439\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4265 - f1_m: 0.8233\n",
      "Epoch 00004: val_loss improved from 0.53367 to 0.40904, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 704ms/step - loss: 0.4265 - f1_m: 0.8233 - val_loss: 0.4090 - val_f1_m: 0.8015\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3708 - f1_m: 0.8472\n",
      "Epoch 00005: val_loss improved from 0.40904 to 0.40070, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 710ms/step - loss: 0.3708 - f1_m: 0.8472 - val_loss: 0.4007 - val_f1_m: 0.8197\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3191 - f1_m: 0.8749\n",
      "Epoch 00006: val_loss did not improve from 0.40070\n",
      "123/123 [==============================] - 87s 709ms/step - loss: 0.3191 - f1_m: 0.8749 - val_loss: 0.4494 - val_f1_m: 0.8331\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2892 - f1_m: 0.8841\n",
      "Epoch 00007: val_loss improved from 0.40070 to 0.36519, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 707ms/step - loss: 0.2892 - f1_m: 0.8841 - val_loss: 0.3652 - val_f1_m: 0.8446\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2710 - f1_m: 0.8984\n",
      "Epoch 00008: val_loss improved from 0.36519 to 0.26549, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 707ms/step - loss: 0.2710 - f1_m: 0.8984 - val_loss: 0.2655 - val_f1_m: 0.8926\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2520 - f1_m: 0.9069\n",
      "Epoch 00009: val_loss did not improve from 0.26549\n",
      "123/123 [==============================] - 84s 679ms/step - loss: 0.2520 - f1_m: 0.9069 - val_loss: 0.2728 - val_f1_m: 0.9024\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2303 - f1_m: 0.9063\n",
      "Epoch 00010: val_loss improved from 0.26549 to 0.24523, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 66s 534ms/step - loss: 0.2303 - f1_m: 0.9063 - val_loss: 0.2452 - val_f1_m: 0.9004\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1937 - f1_m: 0.9198\n",
      "Epoch 00011: val_loss improved from 0.24523 to 0.24226, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 129s 1s/step - loss: 0.1937 - f1_m: 0.9198 - val_loss: 0.2423 - val_f1_m: 0.8831\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1895 - f1_m: 0.9256\n",
      "Epoch 00012: val_loss improved from 0.24226 to 0.24214, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 721s 6s/step - loss: 0.1895 - f1_m: 0.9256 - val_loss: 0.2421 - val_f1_m: 0.9036\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1675 - f1_m: 0.9345\n",
      "Epoch 00013: val_loss improved from 0.24214 to 0.16004, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 0.1675 - f1_m: 0.9345 - val_loss: 0.1600 - val_f1_m: 0.9452\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1515 - f1_m: 0.9414\n",
      "Epoch 00014: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 85s 693ms/step - loss: 0.1515 - f1_m: 0.9414 - val_loss: 0.2484 - val_f1_m: 0.8925\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1499 - f1_m: 0.9460\n",
      "Epoch 00015: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 88s 718ms/step - loss: 0.1499 - f1_m: 0.9460 - val_loss: 0.1634 - val_f1_m: 0.9348\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1359 - f1_m: 0.9500\n",
      "Epoch 00016: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 92s 745ms/step - loss: 0.1359 - f1_m: 0.9500 - val_loss: 0.1662 - val_f1_m: 0.9421\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1199 - f1_m: 0.9542\n",
      "Epoch 00017: val_loss did not improve from 0.16004\n",
      "123/123 [==============================] - 85s 694ms/step - loss: 0.1199 - f1_m: 0.9542 - val_loss: 0.3139 - val_f1_m: 0.8634\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(100, activation='relu'))\n",
    "model4.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[f1_m])\n",
    "\n",
    "history_4 = model4.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_5, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_aug_5.npy',history_4.history)\n",
    "modelBW_aug_5 = keras.models.load_model('models/modelBW_aug_5.h5', custom_objects=dependencies)\n",
    "historyBW_aug_5=np.load('models/historyBW_aug_5.npy',allow_pickle='TRUE').item()\n",
    "timesBW_aug_5 = time_callback.times\n",
    "save_times(modelBW_aug_5, timesBW_aug_5,'modelBW_aug_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_4224/2105229695.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m pre_trained=tf.keras.applications.resnet50.ResNet50(\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                     \u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0m\u001b[0;32m    475\u001b[0m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m   \u001b[1;31m# Determine proper input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m   input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[0;32m    152\u001b[0m       \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[0mdefault_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdefault_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         raise ValueError('When setting `include_top=True` '\n\u001b[0m\u001b[0;32m    344\u001b[0m                          \u001b[1;34m'and loading `imagenet` weights, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                          '`input_shape` should be ' + str(default_shape) + '.')\n",
      "\u001b[1;31mValueError\u001b[0m: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3)."
     ]
    }
   ],
   "source": [
    "pre_trained=tf.keras.applications.resnet50.ResNet50(\n",
    "                                                    include_top=True,\n",
    "                                                    input_shape=(150,150,1),\n",
    "                                                    weights='imagenet',\n",
    "                                                    input_tensor=None,\n",
    "                                               \n",
    "                                                    pooling=None,\n",
    "                                                    classes=1000\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98_H4yeejpEj",
    "outputId": "5f83067c-ff2c-4111-c887-b5a5af86f11f"
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.ResNet50(\n",
    "                                        weights='imagenet',  \n",
    "                                        input_shape=(150, 150, 3),\n",
    "                                   \n",
    "                                        include_top=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_trans = callback(\"\\model_trans.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oEhZuO0OOQya"
   },
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Input \n",
    "\n",
    "# resnet = keras.applications.ResNet50(weights='imagenet',include_top='FALSE') \n",
    "\n",
    "# input_tensor = Input(shape=(150,150,1) )\n",
    "# x = layers.Conv2D(3,(3,3),padding='same')(input_tensor)    # x has a dimension of (IMG_SIZE,IMG_SIZE,3)\n",
    "# out = resnet (x) \n",
    "\n",
    "# model_trans = keras.Model(inputs=input_tensor,outputs=out)\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalMaxPooling2D()(x)\n",
    "outputs = keras.layers.Dense(3)(x)\n",
    "model_trans = keras.Model(inputs, outputs)\n",
    "model_trans.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = [f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "qOY98X1oOYx1"
   },
   "outputs": [],
   "source": [
    "# # callbacks\n",
    "\n",
    "# # lr_reduce = ReduceLROnPlateau(monitor='val_binary_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=23)\n",
    "# mc = ModelCheckpoint('MODEL_trans.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrvCSlonO5o1",
    "outputId": "7654dae5-013d-4589-8589-e9491339213c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "123/123 [==============================] - ETA: 0s - loss: 8.2735 - f1_m: 0.4659\n",
      "Epoch 00001: val_loss improved from inf to 8.61032, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\model_trans.h5\n",
      "123/123 [==============================] - 254s 2s/step - loss: 8.2735 - f1_m: 0.4659 - val_loss: 8.6103 - val_f1_m: 0.4527\n",
      "Epoch 2/20\n",
      "123/123 [==============================] - ETA: 0s - loss: 8.6147 - f1_m: 0.4655\n",
      "Epoch 00002: val_loss improved from 8.61032 to 8.61032, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\model_trans.h5\n",
      "123/123 [==============================] - 211s 2s/step - loss: 8.6147 - f1_m: 0.4655 - val_loss: 8.6103 - val_f1_m: 0.4585\n",
      "Epoch 3/20\n",
      "123/123 [==============================] - ETA: 0s - loss: 8.6147 - f1_m: 0.4652\n",
      "Epoch 00003: val_loss did not improve from 8.61032\n",
      "123/123 [==============================] - 229s 2s/step - loss: 8.6147 - f1_m: 0.4652 - val_loss: 8.6103 - val_f1_m: 0.4585\n",
      "Epoch 4/20\n",
      "106/123 [========================>.....] - ETA: 29s - loss: 8.6890 - f1_m: 0.4613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_4224/3777705998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Batch size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m hist_trans = model_trans.fit(train_generator_rgb,\n\u001b[0m\u001b[0;32m      5\u001b[0m                          \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator_rgb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Epochs\n",
    "epochs = 20\n",
    "# Batch size\n",
    "hist_trans = model_trans.fit(train_generator_rgb,\n",
    "                            epochs = epochs,\n",
    "                            validation_data = val_generator_rgb,\n",
    "                            callbacks=callbacks_trans, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp/ipykernel_7176/1856620179.py:6: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_score = modelBW.evaluate_generator(test_generator)\n"
     ]
    }
   ],
   "source": [
    "preds = modelBW.predict(test_generator)\n",
    "predicted_class_indices = np.argmax(preds, axis=1)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "cm = confusion_matrix(test_labels, predicted_class_indices)\n",
    "test_score = modelBW.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        71\n",
      "           1       0.92      0.97      0.95       142\n",
      "           2       0.97      0.97      0.97        93\n",
      "\n",
      "    accuracy                           0.94       306\n",
      "   macro avg       0.94      0.92      0.93       306\n",
      "weighted avg       0.94      0.94      0.94       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_generator.labels, predicted_class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelBW.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_score_modelBW = modelBW.evaluate_generator(test_generator)\n",
    "# test_score_modelBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo sem aug BW\n",
    "#  ---- dropout augmentation\n",
    "\n",
    "# Modelo sem aug RGB\n",
    "#  ---- dropout augmentation\n",
    "\n",
    "# funoes dos plots\n",
    "\n",
    "# time function comparison"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e16194cf3a231c7e85fd3da1ceecb74b106a13d038ee6c4a53eff2850ad794"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
