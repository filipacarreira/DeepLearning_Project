{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from os import path\n",
    "from numpy.random import seed\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from keras import layers,models\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tensorflow import random as tfrandom\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback, CSVLogger\n",
    "import time\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import math\n",
    "#from tensorflow import set_random_seed\n",
    "import cv2\n",
    "\n",
    "# to assure reproducibility\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Utilizador\\\\Desktop\\\\2_semestre_DS\\\\Deep_Learning\\\\DL_GroupProject\\\\DeepLearning_Group_Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path=(base_path+r\"\\tumor_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the images to 1_xx, 2_xx, 3_xx, by the labels \n",
    "\n",
    "for _, letter in enumerate(os.listdir(dir_path)):\n",
    "    folder_letter = os.path.join(dir_path, letter)\n",
    " \n",
    "    counts=0\n",
    "    for _, image in enumerate(os.listdir(folder_letter)):\n",
    "        \n",
    "        dst=image\n",
    "    \n",
    "        if '_' in dst:\n",
    "            continue\n",
    "        else:\n",
    "            dst = str(letter) + \"_\" + str(counts) + \".png\"\n",
    "            #print(dst)\n",
    "            src = os.path.join(folder_letter, image)\n",
    "            dst = os.path.join(folder_letter, dst)\n",
    "            print(counts)\n",
    "            os.rename(src, dst)\n",
    "            \n",
    "        counts=counts+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories for the train, val and test splits\n",
    "train_path = os.path.join(dir_path, 'train')\n",
    "val_path = os.path.join(dir_path, 'validation')\n",
    "test_path = os.path.join(dir_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdir(mydir):\n",
    "    try:\n",
    "        os.mkdir(mydir)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "# create the directories\n",
    "\n",
    "createdir(train_path)\n",
    "createdir(val_path)\n",
    "createdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the directories for each label for each train, validation and test folders\n",
    "count=0\n",
    "for dir in [train_path, val_path, test_path]:\n",
    "    count+=1\n",
    "    for letter in ['1','2','3']:\n",
    "        if count == 1:\n",
    "            createdir(os.path.join(dir,str(\"train_{0}\".format(str(letter)))))\n",
    "        elif count == 2:\n",
    "            createdir(os.path.join(dir,str(\"val_{0}\".format(str(letter)))))   \n",
    "        elif count == 3:\n",
    "            createdir(os.path.join(dir,str(\"test_{0}\".format(str(letter)))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "break\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# copy all the images for the train folder to then split them for validation and test folders \n",
    "\n",
    "count=0\n",
    "\n",
    "for dir_ in [train_path+r'\\train_1', train_path+r'\\train_2', train_path+r'\\train_3']:\n",
    "        if len(os.listdir(dir_)) != 0:\n",
    "            print('break')\n",
    "            for f in os.listdir(dir_):\n",
    "                os.remove(os.path.join(dir_, f))\n",
    "                \n",
    "for dir in [dir_path+r\"\\1\", dir_path+r\"\\2\", dir_path+r\"\\3\"]:\n",
    "    count+=1\n",
    "    \n",
    "    if count == 1:\n",
    "        copy_tree(dir, train_path+r'\\train_1')\n",
    "    elif count==2:\n",
    "        copy_tree(dir, train_path+r'\\train_2')\n",
    "    elif count==3:\n",
    "        copy_tree(dir, train_path+r'\\train_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion we want for train, val_test and the test datasets\n",
    "prop_train=0.80\n",
    "prop_val_test=0.20\n",
    "prop_test=0.50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'label1':708,'label2':1426,'label3':930}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "break\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# input images in VALIDATION\n",
    "\n",
    "count=0\n",
    "for index, letter in enumerate(os.listdir(train_path)):\n",
    "    count+=1\n",
    "    folder_letter_source = os.path.join(train_path, letter)\n",
    "    folder_letter_destiny_val = os.path.join(val_path, str(\"val_{0}\".format(str(count))))\n",
    "\n",
    "    images_val = random.sample(os.listdir(folder_letter_source), k=round(prop_val_test*labels['label{0}'.format(str(count))]))\n",
    "    count1=0\n",
    "    \n",
    "    for image in images_val:\n",
    "        count1+=1\n",
    "        if count1==1 and len(os.listdir(folder_letter_destiny_val)) != 0:\n",
    "            print('break')\n",
    "            for f in os.listdir(folder_letter_destiny_val):\n",
    "                os.remove(os.path.join(folder_letter_destiny_val, f))\n",
    "            \n",
    "        src = os.path.join(folder_letter_source, image)\n",
    "        dst = os.path.join(folder_letter_destiny_val, image)\n",
    "        shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label1': 142, 'label2': 285, 'label3': 186}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['label1']=round(labels['label1']*prop_val_test)\n",
    "labels['label2']=round(labels['label2']*prop_val_test)\n",
    "labels['label3']=round(labels['label3']*prop_val_test)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break\n",
      "break\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "# input images in TEST\n",
    "\n",
    "count=0\n",
    "for index, letter in enumerate(os.listdir(val_path)):\n",
    "    count+=1\n",
    "    folder_letter_source = os.path.join(val_path, letter)\n",
    "    folder_letter_destiny_test = os.path.join(test_path, str(\"test_{0}\".format(str(count))))\n",
    "\n",
    "    images_val = random.sample(os.listdir(folder_letter_source), k=round(prop_test*labels['label{0}'.format(str(count))]))\n",
    "    count1=0\n",
    "    \n",
    "    for image in images_val:\n",
    "        count1+=1\n",
    "        if count1==1 and len(os.listdir(folder_letter_destiny_test)) != 0:\n",
    "            print('break')\n",
    "            for f in os.listdir(folder_letter_destiny_test):\n",
    "                os.remove(os.path.join(folder_letter_destiny_test, f))\n",
    "            \n",
    "        src = os.path.join(folder_letter_source, image)\n",
    "        dst = os.path.join(folder_letter_destiny_test, image)\n",
    "        shutil.move(src, dst)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen_aug=ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    #rotation_range=50,\n",
    "                    rotation_range=10,\n",
    "                    shear_range=0.05)\n",
    "                    #horizontal_flip=True )\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 images belonging to 3 classes.\n",
      "Found 307 images belonging to 3 classes.\n",
      "Found 306 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(150, 150),  \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(150, 150), \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    seed=42,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 images belonging to 3 classes.\n",
      "Found 2451 images belonging to 3 classes.\n",
      "Found 307 images belonging to 3 classes.\n",
      "Found 306 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator_rgb = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    seed=42\n",
    ")\n",
    "# AUGMENTED\n",
    "train_generator_aug_rgb = train_datagen_aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "val_generator_rgb = val_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(150, 150),  \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator_rgb = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(150, 150), \n",
    "    batch_size=20,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    seed=42,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAPTED FROM https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_times(model, times,name_model):\n",
    "  \n",
    "    times_dict = {'Model': ['Model {}'.format(str(name_model))]}\n",
    "    for idx, time in enumerate(times):\n",
    "        times_dict[idx] = times[idx]\n",
    "    df_save_times = pd.DataFrame(times_dict)\n",
    "\n",
    "    if os.path.exists(r'.\\models\\models_times.csv'):\n",
    "        df_save_times.to_csv(r'.\\models\\models_times.csv', mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df_save_times.to_csv(r'.\\models\\models_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(his):\n",
    "    f1 = his['f1_m']\n",
    "    f1_val=his['val_f1_m']\n",
    "    loss = his['loss']\n",
    "    loss_val=his['val_loss']\n",
    "\n",
    "    epochs=range(1,len(f1)+1)\n",
    "\n",
    "    plt.plot(epochs, f1,'bo',label='Training F1')\n",
    "    plt.plot(epochs, f1_val,'b',label='Validation F1')\n",
    "    plt.title('Training and Validation F1 score')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss,'bo',label='Training loss')\n",
    "    plt.plot(epochs, loss_val,'b',label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.legend()\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(filename):\n",
    "  callname_list=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=4),\n",
    "            keras.callbacks.ModelCheckpoint(filepath=os.path.join(base_path+ \"\\models\")+filename, monitor='val_loss',mode='min',verbose=1, save_best_only=True)\n",
    "            ,time_callback]\n",
    "\n",
    "  return callname_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {\n",
    "    'f1_m': f1_m\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=20 \n",
    "TRAINING_SIZE = 2451 \n",
    "VALIDATION_SIZE = 307 \n",
    "\n",
    "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / BATCH_SIZE)) \n",
    "steps_per_epoch = compute_steps_per_epoch(TRAINING_SIZE) \n",
    "val_steps = compute_steps_per_epoch(VALIDATION_SIZE) \n",
    "\n",
    "print(steps_per_epoch)\n",
    "print(val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW = callback(\"\\modelBW.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_21084/946214897.py:17: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.8207 - f1_m: 0.4929\n",
      "Epoch 00001: val_loss improved from inf to 0.66708, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 109s 888ms/step - loss: 0.8207 - f1_m: 0.4929 - val_loss: 0.6671 - val_f1_m: 0.6100\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6018 - f1_m: 0.7187\n",
      "Epoch 00002: val_loss improved from 0.66708 to 0.54838, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 112s 913ms/step - loss: 0.6018 - f1_m: 0.7187 - val_loss: 0.5484 - val_f1_m: 0.7464\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5038 - f1_m: 0.7746\n",
      "Epoch 00003: val_loss improved from 0.54838 to 0.49370, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 92s 745ms/step - loss: 0.5038 - f1_m: 0.7746 - val_loss: 0.4937 - val_f1_m: 0.8045\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3833 - f1_m: 0.8381\n",
      "Epoch 00004: val_loss did not improve from 0.49370\n",
      "123/123 [==============================] - 99s 803ms/step - loss: 0.3833 - f1_m: 0.8381 - val_loss: 0.5746 - val_f1_m: 0.7611\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3312 - f1_m: 0.8615\n",
      "Epoch 00005: val_loss improved from 0.49370 to 0.43951, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 93s 757ms/step - loss: 0.3312 - f1_m: 0.8615 - val_loss: 0.4395 - val_f1_m: 0.8048\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3008 - f1_m: 0.8762\n",
      "Epoch 00006: val_loss improved from 0.43951 to 0.39341, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 100s 815ms/step - loss: 0.3008 - f1_m: 0.8762 - val_loss: 0.3934 - val_f1_m: 0.8070\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2677 - f1_m: 0.8914\n",
      "Epoch 00007: val_loss improved from 0.39341 to 0.34098, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 106s 864ms/step - loss: 0.2677 - f1_m: 0.8914 - val_loss: 0.3410 - val_f1_m: 0.8626\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1884 - f1_m: 0.9278\n",
      "Epoch 00008: val_loss improved from 0.34098 to 0.33506, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 105s 852ms/step - loss: 0.1884 - f1_m: 0.9278 - val_loss: 0.3351 - val_f1_m: 0.8702\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1655 - f1_m: 0.9312\n",
      "Epoch 00009: val_loss did not improve from 0.33506\n",
      "123/123 [==============================] - 90s 730ms/step - loss: 0.1655 - f1_m: 0.9312 - val_loss: 0.3644 - val_f1_m: 0.8431\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1443 - f1_m: 0.9408\n",
      "Epoch 00010: val_loss did not improve from 0.33506\n",
      "123/123 [==============================] - 102s 825ms/step - loss: 0.1443 - f1_m: 0.9408 - val_loss: 0.3549 - val_f1_m: 0.8696\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0978 - f1_m: 0.9669\n",
      "Epoch 00011: val_loss improved from 0.33506 to 0.26372, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW.h5\n",
      "123/123 [==============================] - 109s 883ms/step - loss: 0.0978 - f1_m: 0.9669 - val_loss: 0.2637 - val_f1_m: 0.8924\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0801 - f1_m: 0.9717\n",
      "Epoch 00012: val_loss did not improve from 0.26372\n",
      "123/123 [==============================] - 106s 860ms/step - loss: 0.0801 - f1_m: 0.9717 - val_loss: 0.2891 - val_f1_m: 0.9031\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0829 - f1_m: 0.9683\n",
      "Epoch 00013: val_loss did not improve from 0.26372\n",
      "123/123 [==============================] - 106s 864ms/step - loss: 0.0829 - f1_m: 0.9683 - val_loss: 0.3032 - val_f1_m: 0.8894\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0587 - f1_m: 0.9795\n",
      "Epoch 00014: val_loss did not improve from 0.26372\n",
      "123/123 [==============================] - 107s 871ms/step - loss: 0.0587 - f1_m: 0.9795 - val_loss: 0.2648 - val_f1_m: 0.8974\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0536 - f1_m: 0.9805\n",
      "Epoch 00015: val_loss did not improve from 0.26372\n",
      "123/123 [==============================] - 106s 860ms/step - loss: 0.0536 - f1_m: 0.9805 - val_loss: 0.3423 - val_f1_m: 0.9094\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "history_1st = model.fit_generator(train_generator, callbacks=callbacks_BW, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('models/historyBW.npy',history_1st.history)\n",
    "modelBW = keras.models.load_model('models/modelBW.h5', custom_objects=dependencies)\n",
    "historyBW=np.load('models/historyBW.npy',allow_pickle='TRUE').item()\n",
    "#timesBW = time_callback.times\n",
    "#save_times(modelBW, timesBW,'modelBW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(historyBW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_inc = callback(\"\\modelBW_inc.h5\")\n",
    "#increase the nr of filters through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7821 - f1_m: 0.5629\n",
      "Epoch 00001: val_loss improved from inf to 0.64189, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 66s 536ms/step - loss: 0.7821 - f1_m: 0.5629 - val_loss: 0.6419 - val_f1_m: 0.7159\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5613 - f1_m: 0.7450\n",
      "Epoch 00002: val_loss improved from 0.64189 to 0.49001, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 72s 581ms/step - loss: 0.5613 - f1_m: 0.7450 - val_loss: 0.4900 - val_f1_m: 0.7882\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4478 - f1_m: 0.8084\n",
      "Epoch 00003: val_loss did not improve from 0.49001\n",
      "123/123 [==============================] - 71s 579ms/step - loss: 0.4478 - f1_m: 0.8084 - val_loss: 0.5086 - val_f1_m: 0.7724\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3749 - f1_m: 0.8437\n",
      "Epoch 00004: val_loss improved from 0.49001 to 0.42431, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 68s 556ms/step - loss: 0.3749 - f1_m: 0.8437 - val_loss: 0.4243 - val_f1_m: 0.8250\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3148 - f1_m: 0.8668\n",
      "Epoch 00005: val_loss improved from 0.42431 to 0.38761, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 56s 456ms/step - loss: 0.3148 - f1_m: 0.8668 - val_loss: 0.3876 - val_f1_m: 0.8199\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2770 - f1_m: 0.8896\n",
      "Epoch 00006: val_loss improved from 0.38761 to 0.34491, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 52s 421ms/step - loss: 0.2770 - f1_m: 0.8896 - val_loss: 0.3449 - val_f1_m: 0.8434\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2063 - f1_m: 0.9192\n",
      "Epoch 00007: val_loss did not improve from 0.34491\n",
      "123/123 [==============================] - 51s 417ms/step - loss: 0.2063 - f1_m: 0.9192 - val_loss: 0.3650 - val_f1_m: 0.8571\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1688 - f1_m: 0.9354\n",
      "Epoch 00008: val_loss did not improve from 0.34491\n",
      "123/123 [==============================] - 51s 416ms/step - loss: 0.1688 - f1_m: 0.9354 - val_loss: 0.3608 - val_f1_m: 0.8699\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1347 - f1_m: 0.9513\n",
      "Epoch 00009: val_loss improved from 0.34491 to 0.29661, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 51s 418ms/step - loss: 0.1347 - f1_m: 0.9513 - val_loss: 0.2966 - val_f1_m: 0.8855\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0945 - f1_m: 0.9642\n",
      "Epoch 00010: val_loss improved from 0.29661 to 0.28545, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 51s 416ms/step - loss: 0.0945 - f1_m: 0.9642 - val_loss: 0.2855 - val_f1_m: 0.8934\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0902 - f1_m: 0.9669\n",
      "Epoch 00011: val_loss improved from 0.28545 to 0.22267, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_inc.h5\n",
      "123/123 [==============================] - 51s 417ms/step - loss: 0.0902 - f1_m: 0.9669 - val_loss: 0.2227 - val_f1_m: 0.9051\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0674 - f1_m: 0.9709\n",
      "Epoch 00012: val_loss did not improve from 0.22267\n",
      "123/123 [==============================] - 51s 418ms/step - loss: 0.0674 - f1_m: 0.9709 - val_loss: 0.2482 - val_f1_m: 0.8958\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0361 - f1_m: 0.9888\n",
      "Epoch 00013: val_loss did not improve from 0.22267\n",
      "123/123 [==============================] - 52s 426ms/step - loss: 0.0361 - f1_m: 0.9888 - val_loss: 0.2965 - val_f1_m: 0.9113\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0589 - f1_m: 0.9780\n",
      "Epoch 00014: val_loss did not improve from 0.22267\n",
      "123/123 [==============================] - 61s 497ms/step - loss: 0.0589 - f1_m: 0.9780 - val_loss: 0.2965 - val_f1_m: 0.9036\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0307 - f1_m: 0.9890\n",
      "Epoch 00015: val_loss did not improve from 0.22267\n",
      "123/123 [==============================] - 52s 420ms/step - loss: 0.0307 - f1_m: 0.9890 - val_loss: 0.2373 - val_f1_m: 0.9279\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(2, 2))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "model2.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "history_2 = model2.fit_generator(train_generator, callbacks=callbacks_BW_inc, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_inc.npy',history_2.history)\n",
    "modelBW_inc = keras.models.load_model('models/modelBW_inc.h5', custom_objects=dependencies)\n",
    "historyBW_inc=np.load('models/historyBW_inc.npy',allow_pickle='TRUE').item()\n",
    "timesBW = time_callback.times\n",
    "save_times(modelBW_inc, timesBW,'modelBW_inc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(historyBW_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDUCING THE NUMBER OF LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_simple = callback(\"\\modelBW_simple.h5\")\n",
    "#increase the nr of filters through the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7221 - f1_m: 0.6164\n",
      "Epoch 00001: val_loss improved from inf to 0.68303, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 81s 657ms/step - loss: 0.7221 - f1_m: 0.6164 - val_loss: 0.6830 - val_f1_m: 0.6612\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5392 - f1_m: 0.7424\n",
      "Epoch 00002: val_loss improved from 0.68303 to 0.53808, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 77s 623ms/step - loss: 0.5392 - f1_m: 0.7424 - val_loss: 0.5381 - val_f1_m: 0.7250\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4233 - f1_m: 0.8077\n",
      "Epoch 00003: val_loss improved from 0.53808 to 0.52782, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 73s 596ms/step - loss: 0.4233 - f1_m: 0.8077 - val_loss: 0.5278 - val_f1_m: 0.7516\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3014 - f1_m: 0.8795\n",
      "Epoch 00004: val_loss improved from 0.52782 to 0.33472, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 74s 603ms/step - loss: 0.3014 - f1_m: 0.8795 - val_loss: 0.3347 - val_f1_m: 0.8626\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2208 - f1_m: 0.9066\n",
      "Epoch 00005: val_loss improved from 0.33472 to 0.29864, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 74s 604ms/step - loss: 0.2208 - f1_m: 0.9066 - val_loss: 0.2986 - val_f1_m: 0.8795\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1628 - f1_m: 0.9323\n",
      "Epoch 00006: val_loss improved from 0.29864 to 0.25906, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 75s 613ms/step - loss: 0.1628 - f1_m: 0.9323 - val_loss: 0.2591 - val_f1_m: 0.8963\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1014 - f1_m: 0.9638\n",
      "Epoch 00007: val_loss improved from 0.25906 to 0.24672, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_simple.h5\n",
      "123/123 [==============================] - 75s 607ms/step - loss: 0.1014 - f1_m: 0.9638 - val_loss: 0.2467 - val_f1_m: 0.9156\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0792 - f1_m: 0.9724\n",
      "Epoch 00008: val_loss did not improve from 0.24672\n",
      "123/123 [==============================] - 76s 614ms/step - loss: 0.0792 - f1_m: 0.9724 - val_loss: 0.3314 - val_f1_m: 0.8800\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0461 - f1_m: 0.9821\n",
      "Epoch 00009: val_loss did not improve from 0.24672\n",
      "123/123 [==============================] - 76s 617ms/step - loss: 0.0461 - f1_m: 0.9821 - val_loss: 0.2677 - val_f1_m: 0.9103\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0406 - f1_m: 0.9850\n",
      "Epoch 00010: val_loss did not improve from 0.24672\n",
      "123/123 [==============================] - 75s 608ms/step - loss: 0.0406 - f1_m: 0.9850 - val_loss: 0.2674 - val_f1_m: 0.9098\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0118 - f1_m: 0.9976\n",
      "Epoch 00011: val_loss did not improve from 0.24672\n",
      "123/123 [==============================] - 75s 609ms/step - loss: 0.0118 - f1_m: 0.9976 - val_loss: 0.4377 - val_f1_m: 0.8973\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "\n",
    "model3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model3.add(layers.MaxPooling2D(2, 2))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D(2, 2))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D(2, 2))\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(100, activation='relu'))\n",
    "model3.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "history_3 = model3.fit_generator(train_generator, callbacks=callbacks_BW_simple, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_simple.npy',history_3.history)\n",
    "modelBW_simple = keras.models.load_model('models/modelBW_simple.h5', custom_objects=dependencies)\n",
    "historyBW_simple=np.load('models/historyBW_simple.npy',allow_pickle='TRUE').item()\n",
    "timesBW_simple = time_callback.times\n",
    "\n",
    "save_times(modelBW_simple, timesBW_simple,'modelBW_simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION AND DROP OUT 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(filename):\n",
    "      callname_list=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "            keras.callbacks.ModelCheckpoint(filepath=os.path.join(base_path+ \"\\models\")+filename, monitor='val_loss',mode='min',verbose=1, save_best_only=True),\n",
    "            time_callback, \n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='min', min_lr=1e-4)]\n",
    "\n",
    "      return callname_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_5 = callback(\"\\modelBW_aug_5.h5\")\n",
    "# aug and dropout\n",
    "# modelBW_aug_rot= rotation10\n",
    "# modelBW_aug=rot50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_23996/1627853678.py:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7707 - f1_m: 0.5844\n",
      "Epoch 00001: val_loss improved from inf to 0.60630, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 85s 688ms/step - loss: 0.7707 - f1_m: 0.5844 - val_loss: 0.6063 - val_f1_m: 0.7426\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5832 - f1_m: 0.7324\n",
      "Epoch 00002: val_loss improved from 0.60630 to 0.49565, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 85s 688ms/step - loss: 0.5832 - f1_m: 0.7324 - val_loss: 0.4957 - val_f1_m: 0.7823\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4590 - f1_m: 0.7996\n",
      "Epoch 00003: val_loss improved from 0.49565 to 0.48035, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 83s 676ms/step - loss: 0.4590 - f1_m: 0.7996 - val_loss: 0.4804 - val_f1_m: 0.8015\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4259 - f1_m: 0.8096\n",
      "Epoch 00004: val_loss improved from 0.48035 to 0.47503, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 82s 669ms/step - loss: 0.4259 - f1_m: 0.8096 - val_loss: 0.4750 - val_f1_m: 0.7915\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3642 - f1_m: 0.8462\n",
      "Epoch 00005: val_loss improved from 0.47503 to 0.37036, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 82s 668ms/step - loss: 0.3642 - f1_m: 0.8462 - val_loss: 0.3704 - val_f1_m: 0.8257\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3174 - f1_m: 0.8657\n",
      "Epoch 00006: val_loss did not improve from 0.37036\n",
      "123/123 [==============================] - 83s 677ms/step - loss: 0.3174 - f1_m: 0.8657 - val_loss: 0.3802 - val_f1_m: 0.8208\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2885 - f1_m: 0.8797\n",
      "Epoch 00007: val_loss improved from 0.37036 to 0.32327, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 82s 664ms/step - loss: 0.2885 - f1_m: 0.8797 - val_loss: 0.3233 - val_f1_m: 0.8782\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2397 - f1_m: 0.9020\n",
      "Epoch 00008: val_loss improved from 0.32327 to 0.26256, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 84s 686ms/step - loss: 0.2397 - f1_m: 0.9020 - val_loss: 0.2626 - val_f1_m: 0.8857\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2326 - f1_m: 0.9056\n",
      "Epoch 00009: val_loss improved from 0.26256 to 0.25083, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 91s 738ms/step - loss: 0.2326 - f1_m: 0.9056 - val_loss: 0.2508 - val_f1_m: 0.8862\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1741 - f1_m: 0.9318\n",
      "Epoch 00010: val_loss improved from 0.25083 to 0.22790, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 84s 680ms/step - loss: 0.1741 - f1_m: 0.9318 - val_loss: 0.2279 - val_f1_m: 0.9104\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1670 - f1_m: 0.9337\n",
      "Epoch 00011: val_loss improved from 0.22790 to 0.20373, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 82s 663ms/step - loss: 0.1670 - f1_m: 0.9337 - val_loss: 0.2037 - val_f1_m: 0.9187\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1388 - f1_m: 0.9435\n",
      "Epoch 00012: val_loss did not improve from 0.20373\n",
      "123/123 [==============================] - 82s 668ms/step - loss: 0.1388 - f1_m: 0.9435 - val_loss: 0.2046 - val_f1_m: 0.9223\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1357 - f1_m: 0.9528\n",
      "Epoch 00013: val_loss improved from 0.20373 to 0.16640, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 85s 691ms/step - loss: 0.1357 - f1_m: 0.9528 - val_loss: 0.1664 - val_f1_m: 0.9594\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1083 - f1_m: 0.9557\n",
      "Epoch 00014: val_loss did not improve from 0.16640\n",
      "123/123 [==============================] - 85s 690ms/step - loss: 0.1083 - f1_m: 0.9557 - val_loss: 0.2157 - val_f1_m: 0.9086\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1107 - f1_m: 0.9563\n",
      "Epoch 00015: val_loss did not improve from 0.16640\n",
      "123/123 [==============================] - 82s 665ms/step - loss: 0.1107 - f1_m: 0.9563 - val_loss: 0.1776 - val_f1_m: 0.9406\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0920 - f1_m: 0.9671\n",
      "Epoch 00016: val_loss improved from 0.16640 to 0.14972, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 87s 709ms/step - loss: 0.0920 - f1_m: 0.9671 - val_loss: 0.1497 - val_f1_m: 0.9546\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0831 - f1_m: 0.9724\n",
      "Epoch 00017: val_loss did not improve from 0.14972\n",
      "123/123 [==============================] - 83s 675ms/step - loss: 0.0831 - f1_m: 0.9724 - val_loss: 0.1542 - val_f1_m: 0.9442\n",
      "Epoch 18/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0787 - f1_m: 0.9685\n",
      "Epoch 00018: val_loss improved from 0.14972 to 0.12810, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 81s 660ms/step - loss: 0.0787 - f1_m: 0.9685 - val_loss: 0.1281 - val_f1_m: 0.9500\n",
      "Epoch 19/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0638 - f1_m: 0.9789\n",
      "Epoch 00019: val_loss improved from 0.12810 to 0.12206, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_5.h5\n",
      "123/123 [==============================] - 81s 661ms/step - loss: 0.0638 - f1_m: 0.9789 - val_loss: 0.1221 - val_f1_m: 0.9656\n",
      "Epoch 20/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0547 - f1_m: 0.9822\n",
      "Epoch 00020: val_loss did not improve from 0.12206\n",
      "123/123 [==============================] - 76s 621ms/step - loss: 0.0547 - f1_m: 0.9822 - val_loss: 0.1475 - val_f1_m: 0.9348\n",
      "Epoch 21/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0554 - f1_m: 0.9819\n",
      "Epoch 00021: val_loss did not improve from 0.12206\n",
      "123/123 [==============================] - 65s 530ms/step - loss: 0.0554 - f1_m: 0.9819 - val_loss: 0.1423 - val_f1_m: 0.9411\n",
      "Epoch 22/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0508 - f1_m: 0.9827\n",
      "Epoch 00022: val_loss did not improve from 0.12206\n",
      "123/123 [==============================] - 69s 561ms/step - loss: 0.0508 - f1_m: 0.9827 - val_loss: 0.1512 - val_f1_m: 0.9513\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "\n",
    "model4.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D(2, 2))\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(100, activation='relu'))\n",
    "model4.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "history_4 = model4.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_5, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('models/historyBW_aug_5.npy',history_4.history)\n",
    "modelBW_aug_5 = keras.models.load_model('models/modelBW_aug_5.h5', custom_objects=dependencies)\n",
    "historyBW_aug_5=np.load('models/historyBW_aug_5.npy',allow_pickle='TRUE').item()\n",
    "#timesBW_aug_5 = time_callback.times\n",
    "#save_times(modelBW_aug_5, timesBW_aug_5,'modelBW_aug_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_23996/3959032470.py:6: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 68,   2,   1],\n",
       "       [  7, 134,   1],\n",
       "       [  0,   0,  93]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = modelBW_aug_5.predict(test_generator)\n",
    "predicted_class_indices = np.argmax(preds, axis=1)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "cm = confusion_matrix(test_labels, predicted_class_indices)\n",
    "test_score = modelBW_aug_5.evaluate_generator(test_generator)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10719911754131317 / Test accuracy: 0.965624988079071\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {test_score[0]} / Test accuracy: {test_score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION AND DROP OUT 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_3 = callback(\"\\modelBW_aug_3.h5\")\n",
    "# aug and dropout of 0.3\n",
    "# modelBW_aug=rot50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7330 - f1_m: 0.6117\n",
      "Epoch 00001: val_loss improved from inf to 0.66092, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 73s 592ms/step - loss: 0.7330 - f1_m: 0.6117 - val_loss: 0.6609 - val_f1_m: 0.6600\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5207 - f1_m: 0.7690\n",
      "Epoch 00002: val_loss improved from 0.66092 to 0.46974, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.5207 - f1_m: 0.7690 - val_loss: 0.4697 - val_f1_m: 0.8069\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4352 - f1_m: 0.8097\n",
      "Epoch 00003: val_loss improved from 0.46974 to 0.44493, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 81s 655ms/step - loss: 0.4352 - f1_m: 0.8097 - val_loss: 0.4449 - val_f1_m: 0.8038\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3726 - f1_m: 0.8365\n",
      "Epoch 00004: val_loss improved from 0.44493 to 0.40532, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.3726 - f1_m: 0.8365 - val_loss: 0.4053 - val_f1_m: 0.8228\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3012 - f1_m: 0.8717\n",
      "Epoch 00005: val_loss improved from 0.40532 to 0.33404, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 80s 647ms/step - loss: 0.3012 - f1_m: 0.8717 - val_loss: 0.3340 - val_f1_m: 0.8584\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2560 - f1_m: 0.8891\n",
      "Epoch 00006: val_loss did not improve from 0.33404\n",
      "123/123 [==============================] - 80s 647ms/step - loss: 0.2560 - f1_m: 0.8891 - val_loss: 0.3567 - val_f1_m: 0.8430\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2171 - f1_m: 0.9133\n",
      "Epoch 00007: val_loss improved from 0.33404 to 0.24269, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 80s 653ms/step - loss: 0.2171 - f1_m: 0.9133 - val_loss: 0.2427 - val_f1_m: 0.9140\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1785 - f1_m: 0.9319\n",
      "Epoch 00008: val_loss improved from 0.24269 to 0.18819, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 81s 659ms/step - loss: 0.1785 - f1_m: 0.9319 - val_loss: 0.1882 - val_f1_m: 0.9279\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1562 - f1_m: 0.9413\n",
      "Epoch 00009: val_loss improved from 0.18819 to 0.17479, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_3.h5\n",
      "123/123 [==============================] - 83s 675ms/step - loss: 0.1562 - f1_m: 0.9413 - val_loss: 0.1748 - val_f1_m: 0.9332\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1718 - f1_m: 0.9326\n",
      "Epoch 00010: val_loss did not improve from 0.17479\n",
      "123/123 [==============================] - 81s 659ms/step - loss: 0.1718 - f1_m: 0.9326 - val_loss: 0.2260 - val_f1_m: 0.9122\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1182 - f1_m: 0.9533\n",
      "Epoch 00011: val_loss did not improve from 0.17479\n",
      "123/123 [==============================] - 80s 650ms/step - loss: 0.1182 - f1_m: 0.9533 - val_loss: 0.2125 - val_f1_m: 0.9187\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0957 - f1_m: 0.9624\n",
      "Epoch 00012: val_loss did not improve from 0.17479\n",
      "123/123 [==============================] - 82s 670ms/step - loss: 0.0957 - f1_m: 0.9624 - val_loss: 0.2441 - val_f1_m: 0.9031\n"
     ]
    }
   ],
   "source": [
    "model5 = models.Sequential()\n",
    "\n",
    "model5.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model5.add(layers.MaxPooling2D(2, 2))\n",
    "model5.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D(2, 2))\n",
    "model5.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D(2, 2))\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(layers.Dropout(0.3))\n",
    "model5.add(layers.Dense(100, activation='relu'))\n",
    "model5.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "history_5 = model5.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_3, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('models/historyBW_aug_3.npy',history_5.history)\n",
    "modelBW_aug_3 = keras.models.load_model('models/modelBW_aug_3.h5', custom_objects=dependencies)\n",
    "historyBW_aug_3=np.load('models/historyBW_aug_3.npy',allow_pickle='TRUE').item()\n",
    "#timesBW_aug_3 = time_callback.times\n",
    "#save_times(modelBW_aug_3, timesBW_aug_3,'modelBW_aug_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION AND DROP OUT 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_4 = callback(\"\\modelBW_aug_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_drop(input_drop):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(input_drop))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "    history = model.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_4, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                    validation_data=val_generator, workers=2)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7503 - f1_m: 0.6051\n",
      "Epoch 00001: val_loss improved from inf to 0.69886, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 86s 702ms/step - loss: 0.7503 - f1_m: 0.6051 - val_loss: 0.6989 - val_f1_m: 0.7055\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5600 - f1_m: 0.7487\n",
      "Epoch 00002: val_loss improved from 0.69886 to 0.54631, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 84s 684ms/step - loss: 0.5600 - f1_m: 0.7487 - val_loss: 0.5463 - val_f1_m: 0.7568\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4462 - f1_m: 0.8076\n",
      "Epoch 00003: val_loss improved from 0.54631 to 0.50075, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 83s 674ms/step - loss: 0.4462 - f1_m: 0.8076 - val_loss: 0.5008 - val_f1_m: 0.7746\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4073 - f1_m: 0.8189\n",
      "Epoch 00004: val_loss improved from 0.50075 to 0.42241, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 0.4073 - f1_m: 0.8189 - val_loss: 0.4224 - val_f1_m: 0.8188\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.3464 - f1_m: 0.8527\n",
      "Epoch 00005: val_loss improved from 0.42241 to 0.36109, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 80s 648ms/step - loss: 0.3464 - f1_m: 0.8527 - val_loss: 0.3611 - val_f1_m: 0.8242\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2919 - f1_m: 0.8760\n",
      "Epoch 00006: val_loss improved from 0.36109 to 0.32845, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 86s 696ms/step - loss: 0.2919 - f1_m: 0.8760 - val_loss: 0.3285 - val_f1_m: 0.8284\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2490 - f1_m: 0.9034\n",
      "Epoch 00007: val_loss improved from 0.32845 to 0.27012, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.2490 - f1_m: 0.9034 - val_loss: 0.2701 - val_f1_m: 0.9062\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.2254 - f1_m: 0.9118\n",
      "Epoch 00008: val_loss improved from 0.27012 to 0.20791, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 80s 652ms/step - loss: 0.2254 - f1_m: 0.9118 - val_loss: 0.2079 - val_f1_m: 0.9359\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1911 - f1_m: 0.9208\n",
      "Epoch 00009: val_loss did not improve from 0.20791\n",
      "123/123 [==============================] - 79s 644ms/step - loss: 0.1911 - f1_m: 0.9208 - val_loss: 0.2379 - val_f1_m: 0.9045\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1621 - f1_m: 0.9312\n",
      "Epoch 00010: val_loss did not improve from 0.20791\n",
      "123/123 [==============================] - 80s 647ms/step - loss: 0.1621 - f1_m: 0.9312 - val_loss: 0.2607 - val_f1_m: 0.8875\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1426 - f1_m: 0.9473\n",
      "Epoch 00011: val_loss improved from 0.20791 to 0.20206, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 83s 673ms/step - loss: 0.1426 - f1_m: 0.9473 - val_loss: 0.2021 - val_f1_m: 0.9161\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1296 - f1_m: 0.9501\n",
      "Epoch 00012: val_loss improved from 0.20206 to 0.15538, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 80s 653ms/step - loss: 0.1296 - f1_m: 0.9501 - val_loss: 0.1554 - val_f1_m: 0.9442\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1007 - f1_m: 0.9596\n",
      "Epoch 00013: val_loss did not improve from 0.15538\n",
      "123/123 [==============================] - 78s 634ms/step - loss: 0.1007 - f1_m: 0.9596 - val_loss: 0.2314 - val_f1_m: 0.9149\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0940 - f1_m: 0.9644\n",
      "Epoch 00014: val_loss improved from 0.15538 to 0.14607, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_4.h5\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.0940 - f1_m: 0.9644 - val_loss: 0.1461 - val_f1_m: 0.9594\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1058 - f1_m: 0.9589\n",
      "Epoch 00015: val_loss did not improve from 0.14607\n",
      "123/123 [==============================] - 78s 631ms/step - loss: 0.1058 - f1_m: 0.9589 - val_loss: 0.1877 - val_f1_m: 0.9281\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0928 - f1_m: 0.9626\n",
      "Epoch 00016: val_loss did not improve from 0.14607\n",
      "123/123 [==============================] - 77s 626ms/step - loss: 0.0928 - f1_m: 0.9626 - val_loss: 0.2446 - val_f1_m: 0.8884\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0692 - f1_m: 0.9762\n",
      "Epoch 00017: val_loss did not improve from 0.14607\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.0692 - f1_m: 0.9762 - val_loss: 0.1509 - val_f1_m: 0.9379\n"
     ]
    }
   ],
   "source": [
    "history_6=create_model_drop(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/historyBW_aug_4.npy',history_6.history)\n",
    "modelBW_aug_4 = keras.models.load_model('models/modelBW_aug_4.h5', custom_objects=dependencies)\n",
    "historyBW_aug_4=np.load('models/historyBW_aug_4.npy',allow_pickle='TRUE').item()\n",
    "timesBW_aug_4 = time_callback.times\n",
    "save_times(modelBW_aug_4, timesBW_aug_4,'modelBW_aug_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION AND regularization L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_BW_aug_l1 = callback(\"\\modelBW_aug_l1.h5\")\n",
    "# modelBW_aug=rot50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.1510 - f1_m: 0.5694\n",
      "Epoch 00001: val_loss improved from inf to 1.13698, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 82s 665ms/step - loss: 1.1510 - f1_m: 0.5694 - val_loss: 1.1370 - val_f1_m: 0.7161\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.8730 - f1_m: 0.6908\n",
      "Epoch 00002: val_loss improved from 1.13698 to 0.77076, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 79s 641ms/step - loss: 0.8730 - f1_m: 0.6908 - val_loss: 0.7708 - val_f1_m: 0.7325\n",
      "Epoch 3/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7720 - f1_m: 0.7526\n",
      "Epoch 00003: val_loss did not improve from 0.77076\n",
      "123/123 [==============================] - 77s 625ms/step - loss: 0.7720 - f1_m: 0.7526 - val_loss: 0.7942 - val_f1_m: 0.7207\n",
      "Epoch 4/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.7109 - f1_m: 0.7747\n",
      "Epoch 00004: val_loss improved from 0.77076 to 0.72919, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 83s 679ms/step - loss: 0.7109 - f1_m: 0.7747 - val_loss: 0.7292 - val_f1_m: 0.7690\n",
      "Epoch 5/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6654 - f1_m: 0.8023\n",
      "Epoch 00005: val_loss improved from 0.72919 to 0.65054, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.6654 - f1_m: 0.8023 - val_loss: 0.6505 - val_f1_m: 0.7979\n",
      "Epoch 6/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6348 - f1_m: 0.8190\n",
      "Epoch 00006: val_loss did not improve from 0.65054\n",
      "123/123 [==============================] - 78s 632ms/step - loss: 0.6348 - f1_m: 0.8190 - val_loss: 0.7823 - val_f1_m: 0.7772\n",
      "Epoch 7/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6222 - f1_m: 0.8229\n",
      "Epoch 00007: val_loss did not improve from 0.65054\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 0.6222 - f1_m: 0.8229 - val_loss: 0.7267 - val_f1_m: 0.7796\n",
      "Epoch 8/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.6152 - f1_m: 0.8247\n",
      "Epoch 00008: val_loss improved from 0.65054 to 0.62099, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 77s 629ms/step - loss: 0.6152 - f1_m: 0.8247 - val_loss: 0.6210 - val_f1_m: 0.8199\n",
      "Epoch 9/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5698 - f1_m: 0.8530\n",
      "Epoch 00009: val_loss did not improve from 0.62099\n",
      "123/123 [==============================] - 88s 713ms/step - loss: 0.5698 - f1_m: 0.8530 - val_loss: 0.6228 - val_f1_m: 0.8327\n",
      "Epoch 10/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5464 - f1_m: 0.8683\n",
      "Epoch 00010: val_loss improved from 0.62099 to 0.57653, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 81s 656ms/step - loss: 0.5464 - f1_m: 0.8683 - val_loss: 0.5765 - val_f1_m: 0.8576\n",
      "Epoch 11/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5580 - f1_m: 0.8652\n",
      "Epoch 00011: val_loss improved from 0.57653 to 0.57367, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 84s 683ms/step - loss: 0.5580 - f1_m: 0.8652 - val_loss: 0.5737 - val_f1_m: 0.8555\n",
      "Epoch 12/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5119 - f1_m: 0.8925\n",
      "Epoch 00012: val_loss improved from 0.57367 to 0.53662, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 83s 671ms/step - loss: 0.5119 - f1_m: 0.8925 - val_loss: 0.5366 - val_f1_m: 0.8836\n",
      "Epoch 13/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5354 - f1_m: 0.8842\n",
      "Epoch 00013: val_loss did not improve from 0.53662\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.5354 - f1_m: 0.8842 - val_loss: 0.6269 - val_f1_m: 0.8341\n",
      "Epoch 14/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4981 - f1_m: 0.8991\n",
      "Epoch 00014: val_loss improved from 0.53662 to 0.50996, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 79s 644ms/step - loss: 0.4981 - f1_m: 0.8991 - val_loss: 0.5100 - val_f1_m: 0.9062\n",
      "Epoch 15/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.5116 - f1_m: 0.8938\n",
      "Epoch 00015: val_loss did not improve from 0.50996\n",
      "123/123 [==============================] - 80s 649ms/step - loss: 0.5116 - f1_m: 0.8938 - val_loss: 0.5247 - val_f1_m: 0.9066\n",
      "Epoch 16/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4801 - f1_m: 0.9074\n",
      "Epoch 00016: val_loss did not improve from 0.50996\n",
      "123/123 [==============================] - 79s 642ms/step - loss: 0.4801 - f1_m: 0.9074 - val_loss: 0.5254 - val_f1_m: 0.8993\n",
      "Epoch 17/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4666 - f1_m: 0.9227\n",
      "Epoch 00017: val_loss improved from 0.50996 to 0.46828, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 79s 638ms/step - loss: 0.4666 - f1_m: 0.9227 - val_loss: 0.4683 - val_f1_m: 0.9077\n",
      "Epoch 18/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4718 - f1_m: 0.9209\n",
      "Epoch 00018: val_loss did not improve from 0.46828\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.4718 - f1_m: 0.9209 - val_loss: 0.4759 - val_f1_m: 0.9170\n",
      "Epoch 19/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4412 - f1_m: 0.9378\n",
      "Epoch 00019: val_loss did not improve from 0.46828\n",
      "123/123 [==============================] - 79s 645ms/step - loss: 0.4412 - f1_m: 0.9378 - val_loss: 0.5174 - val_f1_m: 0.9014\n",
      "Epoch 20/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4388 - f1_m: 0.9320\n",
      "Epoch 00020: val_loss improved from 0.46828 to 0.44485, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\modelBW_aug_l1.h5\n",
      "123/123 [==============================] - 78s 637ms/step - loss: 0.4388 - f1_m: 0.9320 - val_loss: 0.4449 - val_f1_m: 0.9295\n",
      "Epoch 21/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4262 - f1_m: 0.9377\n",
      "Epoch 00021: val_loss did not improve from 0.44485\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 0.4262 - f1_m: 0.9377 - val_loss: 0.4711 - val_f1_m: 0.9062\n",
      "Epoch 22/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4573 - f1_m: 0.9285\n",
      "Epoch 00022: val_loss did not improve from 0.44485\n",
      "123/123 [==============================] - 79s 643ms/step - loss: 0.4573 - f1_m: 0.9285 - val_loss: 0.4768 - val_f1_m: 0.9165\n",
      "Epoch 23/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.4303 - f1_m: 0.9452\n",
      "Epoch 00023: val_loss did not improve from 0.44485\n",
      "123/123 [==============================] - 76s 619ms/step - loss: 0.4303 - f1_m: 0.9452 - val_loss: 0.4924 - val_f1_m: 0.9073\n"
     ]
    }
   ],
   "source": [
    "model7 = models.Sequential()\n",
    "\n",
    "model7.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
    "model7.add(layers.MaxPooling2D(2, 2))\n",
    "model7.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D(2, 2))\n",
    "model7.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D(2, 2))\n",
    "model7.add(layers.Flatten())\n",
    "model7.add(layers.Dropout(0.5))\n",
    "model7.add(layers.Dense(100, activation='relu', kernel_regularizer=keras.regularizers.l1(1e-4)))\n",
    "model7.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "\n",
    "history_7 = model7.fit_generator(train_generator_aug, callbacks=callbacks_BW_aug_l1, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('models/historyBW_aug_l1.npy',history_7.history)\n",
    "modelBW_aug_l1 = keras.models.load_model('models/modelBW_aug_l1.h5', custom_objects=dependencies)\n",
    "historyBW_aug_l1=np.load('models/historyBW_aug_l1.npy',allow_pickle='TRUE').item()\n",
    "#timesBW_aug_l1 = time_callback.times\n",
    "#save_times(modelBW_aug_l1, timesBW_aug_l1,'modelBW_aug_l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_trained=tf.keras.applications.ResNet50(\n",
    "#                                                     include_top=True,\n",
    "#                                                     input_shape=(224,224,1),\n",
    "#                                                     weights='imagenet',\n",
    "#                                                     input_tensor=None,\n",
    "                                               \n",
    "#                                                     pooling=None,\n",
    "#                                                     classes=1000\n",
    "#                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_trans = callback(\"\\model_trans.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "base_model=tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\",input_shape=(150,150,3), pooling='max') \n",
    "x=base_model.output\n",
    "x=layers.Dropout(0.4)(x) \n",
    "#x = layers.Dense(100,activation='relu')(x)     \n",
    "output=layers.Dense(3, activation='softmax')(x)\n",
    "model_trans=Model(inputs=base_model.input, outputs=output)\n",
    "model_trans.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 2.3859 - f1_m: 0.6882\n",
      "Epoch 00001: val_loss improved from inf to 187213.20312, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\model_trans.h5\n",
      "123/123 [==============================] - 1118s 9s/step - loss: 2.3859 - f1_m: 0.6882 - val_loss: 187213.2031 - val_f1_m: 0.4701\n",
      "Epoch 2/30\n",
      "123/123 [==============================] - ETA: 0s - loss: 1.2509 - f1_m: 0.6791\n",
      "Epoch 00002: val_loss improved from 187213.20312 to 58592.59766, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\model_trans.h5\n",
      "123/123 [==============================] - 1112s 9s/step - loss: 1.2509 - f1_m: 0.6791 - val_loss: 58592.5977 - val_f1_m: 0.4701\n",
      "Epoch 3/30\n",
      " 18/123 [===>..........................] - ETA: 14:07 - loss: 0.5297 - f1_m: 0.7475"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_19872/886115476.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history_trans = model_trans.fit_generator(train_generator_aug_rgb, callbacks=callbacks_trans, epochs=30, steps_per_epoch=123, validation_steps=16,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                  validation_data=val_generator_rgb, workers=2)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \"\"\"\n\u001b[0;32m   1814\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit_generator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1816\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_trans = model_trans.fit_generator(train_generator_aug_rgb, callbacks=callbacks_trans, epochs=30, steps_per_epoch=123, validation_steps=16,\n",
    "                                 validation_data=val_generator_rgb, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.ResNet50(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(3)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = [f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "oEhZuO0OOQya"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input \n",
    "\n",
    "resnet = keras.applications.ResNet50(weights='imagenet',include_top='FALSE') \n",
    "\n",
    "input_tensor = Input(shape=(150,150,1) )\n",
    "x = layers.Conv2D(3,(3,3),padding='same')(input_tensor)    # x has a dimension of (IMG_SIZE,IMG_SIZE,3)\n",
    "out = resnet (x) \n",
    "\n",
    "model_trans = keras.Model(inputs=input_tensor,outputs=out)\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(150, 150, 1))\n",
    "x = base_model(inputs, training=False)\n",
    "x = keras.layers.GlobalMaxPooling2D()(x)\n",
    "outputs = keras.layers.Dense(3)(x)\n",
    "model_trans = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrvCSlonO5o1",
    "outputId": "7654dae5-013d-4589-8589-e9491339213c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "123/123 [==============================] - ETA: 0s - loss: 12.3960 - f1_m: 0.3031\n",
      "Epoch 00001: val_loss improved from inf to 12.39046, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\model_trans.h5\n",
      "123/123 [==============================] - 166s 1s/step - loss: 12.3960 - f1_m: 0.3031 - val_loss: 12.3905 - val_f1_m: 0.3022\n",
      "Epoch 2/20\n",
      "123/123 [==============================] - ETA: 0s - loss: 12.3960 - f1_m: 0.3034\n",
      "Epoch 00002: val_loss improved from 12.39046 to 12.39046, saving model to c:\\Users\\Utilizador\\Desktop\\2_semestre_DS\\Deep_Learning\\DL_GroupProject\\DeepLearning_Group_Project\\models\\model_trans.h5\n",
      "123/123 [==============================] - 167s 1s/step - loss: 12.3960 - f1_m: 0.3034 - val_loss: 12.3905 - val_f1_m: 0.3022\n",
      "Epoch 3/20\n",
      " 24/123 [====>.........................] - ETA: 2:08 - loss: 12.6258 - f1_m: 0.3104"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\UTILIZ~1\\AppData\\Local\\Temp/ipykernel_23996/3137868709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Batch size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m hist_trans = model.fit(train_generator_trans,\n\u001b[0m\u001b[0;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_generator_trans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics = [f1_m])\n",
    "hist_trans = model.fit(train_generator_aug_rgb,\n",
    "                    epochs = 20,\n",
    "                    validation_data = val_generator_rgb,\n",
    "                    callbacks=callbacks_trans, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input \n",
    "\n",
    "resnet = keras.applications.ResNet50(weights='imagenet',include_top= 'TRUE') \n",
    "\n",
    "input_tensor = Input(shape=(224,224,1) )\n",
    "x = keras.layers.Conv2D(3,(3,3),padding='same')(input_tensor)    # x has a dimension of (IMG_SIZE,IMG_SIZE,3)\n",
    "x = keras.layers.Dense(3)(x)\n",
    "out = resnet (x) \n",
    "\n",
    "model = Model(inputs=input_tensor,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp/ipykernel_7176/1856620179.py:6: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_score = modelBW.evaluate_generator(test_generator)\n"
     ]
    }
   ],
   "source": [
    "preds = modelBW.predict(test_generator)\n",
    "predicted_class_indices = np.argmax(preds, axis=1)\n",
    "test_labels = test_generator.labels\n",
    "\n",
    "cm = confusion_matrix(test_labels, predicted_class_indices)\n",
    "test_score = modelBW.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        71\n",
      "           1       0.92      0.97      0.95       142\n",
      "           2       0.97      0.97      0.97        93\n",
      "\n",
      "    accuracy                           0.94       306\n",
      "   macro avg       0.94      0.92      0.93       306\n",
      "weighted avg       0.94      0.94      0.94       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_generator.labels, predicted_class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelBW.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_score_modelBW = modelBW.evaluate_generator(test_generator)\n",
    "# test_score_modelBW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo sem aug BW\n",
    "#  ---- dropout augmentation\n",
    "\n",
    "# Modelo sem aug RGB\n",
    "#  ---- dropout augmentation\n",
    "\n",
    "# funçoes dos plots\n",
    "\n",
    "# time function comparison"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18e16194cf3a231c7e85fd3da1ceecb74b106a13d038ee6c4a53eff2850ad794"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
